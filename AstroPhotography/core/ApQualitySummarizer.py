# -*- coding: utf-8 -*-
#
#  ApQualitySummarizer.py
#
#  Reads the quality files produced by ap_find_stars.py and writes a
#  summary CSV.
#  
#  Copyright 2020-2021 Dave Strickland <dave.strickland@gmail.com>
#  
#  This program is free software; you can redistribute it and/or modify
#  it under the terms of the GNU General Public License as published by
#  the Free Software Foundation; either version 2 of the License, or
#  (at your option) any later version.
#  
#  This program is distributed in the hope that it will be useful,
#  but WITHOUT ANY WARRANTY; without even the implied warranty of
#  MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
#  GNU General Public License for more details.
#  
#  You should have received a copy of the GNU General Public License
#  along with this program; if not, write to the Free Software
#  Foundation, Inc., 51 Franklin Street, Fifth Floor, Boston,
#  MA 02110-1301, USA.
#  
#  2020-09-04 dks : Initial coding.
#  2021-01-19 dks : Move ApQualitySummarizer into core.

import sys
import logging
from pathlib import Path
import yaml

import numpy as np
from astropy.table import Table

# AstroPhotography includes    
from .. import __version__

class ApQualitySummarizer:
    """
    Summarizes all quality yaml files generated by ApFindStars or
    ap_find_stars.py, writing a single multi-column CSV as output.
    """
    
    def __init__(self, qualdir, 
        sumfile,
        loglevel, 
        walktree,
        qual_pref, 
        qual_suff):
    
        # Initialize logging
        self._loglevel = loglevel
        self._initialize_logger(self._loglevel)
        
        self._qualdir   = qualdir
        self._sumfile   = sumfile
        self._walktree  = walktree
        self._qual_pref = qual_pref
        self._qual_suff = qual_suff
        
        # Generate a list of all the files as pathlib Paths.
        self._path_list = []
        self._find_files()
        if len(self._path_list) == 0:
            self._logger.warning(f'Found zero quality files under {qualdir}. Nothing to do.')
            return
        
        # Read the data
        self._read_files()
        
        # Build the astropy data table
        self._build_summary_table()
        
        # Write out to the summary file.
        self._write_summary_table()
        
        return
        
    def _build_summary_table(self):
        """
        Build an astrtopy table containing the summmary of all the
        quality files, ordered by target:telescope:filter group.
        """
        
        # Columns and their mapping to data items
        # The format of the dictionary is the Table column name
        # followed by a dictionary containing the Table dtype to use (fmt),
        # the subsection of the yaml structure (subsec) and the key within
        # that subsection.
        col_def_dict = {
            'targ:tel:filter':  {'fmt': 'S64', 'subsec':  None, 'kw': None},
            }
        
        # Run through one file to generate extra keys
        # TODO: Limitation, if that file is missing some keys then
        #  that key won't appear in the output, so values of that key 
        #  in other files will not appear.
        tmp_data = self._data_list[0]
        for subsec, subsec_data in tmp_data.items():
            for key, val in subsec_data.items():
                # Special handling for FWHM data
                if 'fwhm_xandy' in key:
                    for subkey in val:
                        if 'num_data' in subkey:
                            fmt = 'i4'
                        else:
                            fmt = 'f8'
                        col_def_dict[subkey] = {'fmt': fmt, 'subsec': subsec, 'kw': subkey}
                elif 'fwhm_x' in key:
                    pass
                elif 'fwhm_y' in key:
                    pass
                else:
                    # Determine type of item
                    if isinstance(val, str):
                        if 'file' in key:
                            fmt='S128'
                        else:
                            fmt='S32'
                    elif isinstance(val, float):
                        fmt='f8'
                    elif isinstance(val, int):
                        fmt='i4'
                    elif isinstance(val, bool):
                        fmt='bool'
                    else:
                        err_msg = (
                            f'Error, unexpected type={type(val)} for'
                            f' key={key} in subsection={subsec}'
                            )
                        self._logger.error(err_msg)
                    col_def_dict[key] = {'fmt': fmt, 'subsec': subsec, 'kw': key}
        
        # Create empty table.
        nrows = len(self._data_list)
        dtype_list=[]
        for key, val in col_def_dict.items():
            dtype_list.append( (key, val['fmt']) )
            
        sum_table = Table(data=np.zeros(nrows, dtype=dtype_list))
        
        # Fill table, processing by index_dict key
        # This seems like it will be slow. There is probably a better way
        # of doing this.
        rowidx = 0
        for ttfkey, ttfval in self._index_dict.items():
            ndata = len(ttfval)
            self._logger.debug(f'Processing target:telescope:filter {ttfkey} with {ndata} datatsets.')

            # Loop over the data_list indices stored in the ttfval
            for idx in ttfval:
                data = self._data_list[idx]
                values_dict = self._extract_values(data, col_def_dict)
                values_dict['targ:tel:filter'] = ttfkey
        
                for odkey, odval in values_dict.items():
                    sum_table[odkey][rowidx] = odval
        
                # Update row index
                rowidx += 1
        
        self._summary_table = sum_table.copy()
        return    
        
    def _extract_values(self, idata, icol_data_dict):
        """
        Extract the data values named in the input column data 
        dictionary from the yaml input data structure.
          
        There is a bit of a hardwired hack to handle the FWHM data.
        """
        
        # keywords that require special handling
        special_kws=['fwhm_val_pix', 'fwhm_val_arcs', 
            'fwhm_err_pix', 'fwhm_err_arcs', 
            'num_data_pts']
        
        out_dict = {}
        for key, valdict in icol_data_dict.items():
            subsec = valdict['subsec']
            kw     = valdict['kw']
            
            # Skip the targ:tel:filter master keyword
            if subsec is None:
                continue
            
            if kw in special_kws:
                if kw in idata[subsec]['fwhm_xandy']:
                    out_dict[kw] = idata[subsec]['fwhm_xandy'][kw]
                else:
                    out_dict[kw] = ''
                    self._logger.warning(f'Missing entry for keyword {kw}, ignoring...')
            else:
                if kw in idata[subsec]:
                    out_dict[kw] = idata[subsec][kw]
                else:
                    out_dict[kw] = ''
                    self._logger.warning(f'Missing entry for keyword {kw}, ignoring...')
        
        return out_dict
    
    def _find_files(self):
        """
        Find all quality files in the specified directory or 
        directory tree.
           
        This function builds a list of pathlib Path objects, not file
        name strings.
        """
        
        # TODO check that qualdir is a valid directory path
        
        # File pattern to look for
        file_pattern = f'{self._qual_pref}*{self._qual_suff}'
        
        # Info message
        in_or_under  = 'in'
        if self._walktree:
            in_or_under = 'under'
        self._logger.info(f'Searching for file matching pattern "{file_pattern}" {in_or_under} {self._qualdir}')
       
        # If walktree is True use rglob, otherwise glob
        if self._walktree:
            for globbed in Path(self._qualdir).rglob(file_pattern):
                self._path_list.append( globbed )
        else:
            for globbed in Path(self._qualdir).glob(file_pattern):
                self._path_list.append( globbed )
        
        num_files = len(self._path_list)
        self._logger.debug(f'Found {num_files} matching path and pattern.')
        return
        
    def _initialize_logger(self, loglevel):
        """
        Initialize and return the logger
        """
        
        self._logger = logging.getLogger('ApQualitySummarizer')
        
        # Check that the input log level is legal
        numeric_level = getattr(logging, loglevel.upper(), None)
        if not isinstance(numeric_level, int):
            raise ValueError('Invalid log level: {}'.format(loglevel))
        self._logger.setLevel(numeric_level)
    
        # create console handler and set level to debug
        ch = logging.StreamHandler()
        ch.setLevel(numeric_level)
    
        # create formatter
        formatter = logging.Formatter('%(asctime)s | %(name)s | %(levelname)s | %(message)s')
    
        # add formatter to ch
        ch.setFormatter(formatter)
    
        # add ch to logger
        self._logger.addHandler(ch)
        return
        
    def _read_files(self):
        """Read all the yaml files"""
        
        # This creates several dictionaries, storing the main yaml
        # data in a list.
      
        # List of yaml dictionaries stored by index.
        self._data_list = []
        
        # Dictionary of unique target/telescope/filter combo with a list
        # of the index/indices within self._data_list at which the yaml
        # data can be found.
        self._index_dict = {}
        
        num_paths = len(self._path_list)
        for idx in range(num_paths):
            path_obj = self._path_list[idx]
            with path_obj.open(mode='r') as f_handle:
                data = yaml.load(f_handle, Loader=yaml.FullLoader)
                if 'image_info' in data:
                    a_target    = data['image_info']['object'].strip()
                    a_telescope = data['image_info']['telescope'].strip()
                    a_filter    = data['image_info']['filter'].strip()
                    
                    # Create key for target/telescope/filter combo
                    key = f'{a_target}:{a_telescope}:{a_filter}'.replace(' ', '_')
                    self._data_list.append( data )
                    if key in self._index_dict:
                        # Key already exists, add to list
                        self._index_dict[key].append( idx )
                    else:
                        # Key does not exist, create key/value pair
                        self._index_dict[key] = [ idx ]
                else:
                    self._logger.warning(f'Input file {str(path_obj)} lacks image_info data. Skipping this file.')
                    
        # Report the number of unique target/telescope/filter groups
        num_groups = len(self._index_dict)
        key_list = []
        for key in self._index_dict:
            key_list.append(key)
        key_str = ', '.join(key_list)
        self._logger.info(f'There are {num_groups} unique target/telescope/filter groupings: {key_str}')
        return

    def _write_summary_table(self):
        """
        Write out a summary of the quality data to a spreadsheet format.
        """
        
        ofmt = 'ascii.csv'
        over = True
        self._summary_table.write(self._sumfile, 
            format=ofmt,
            overwrite=over)
        self._logger.info(f'Wrote quality summary to {self._sumfile}')
        return
        
